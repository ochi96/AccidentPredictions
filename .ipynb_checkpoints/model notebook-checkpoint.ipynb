{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''import relevant libraries'''\n",
    "import os\n",
    "import numpy as np\n",
    "import string\n",
    "from keras import models, layers, regularizers, preprocessing\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Embedding, Flatten, Dense\n",
    "from keras.utils import to_categorical\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt \n",
    "from matplotlib import style\n",
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "import re\n",
    "import matplotlib.pyplot as partial_train_data\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LogisticRegression,Perceptron,SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier  \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC,LinearSVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import cross_val_score,cross_val_predict,train_test_split, KFold\n",
    "from sklearn.metrics import confusion_matrix,precision_score,recall_score,roc_auc_score,precision_recall_curve,roc_curve, accuracy_score\n",
    "from sklearn.preprocessing import OneHotEncoder,StandardScaler, MinMaxScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(128,kernel_regularizer=regularizers.l2(0.003), activation='relu', input_shape=(117,)))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(16,kernel_regularizer=regularizers.l2(0.003),activation='relu'))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(16,kernel_regularizer=regularizers.l2(0.002),activation='relu'))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(4, activation='softmax'))\n",
    "    model.compile(optimizer='rmsprop',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def kfoldvalidation():\n",
    "    train_targets = pd.read_csv('train_targets.csv', delimiter=',', engine='python')\n",
    "    train_data = pd.read_csv('train_data.csv', delimiter=',', engine='python')\n",
    "    one_hot = pd.get_dummies(train_targets, prefix= '_')\n",
    "    train_targets = pd.concat([train_targets,one_hot],axis=1)\n",
    "    train_targets = train_targets.drop(['Degree of the injury'], axis=1)\n",
    "    train_data = train_data.drop(['Accident Description'], axis=1) \n",
    "    print(train_targets.head(10))\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(train_data, train_targets, test_size=0.1, random_state=70)\n",
    "\n",
    "    model = build_model()\n",
    "\n",
    "    model.fit(X_train, y_train, epochs=100, batch_size=20, verbose=1)\n",
    "\n",
    "    results = model.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "    print(results)\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    neural_network = KerasClassifier(build_fn = build_model, epochs=80, batch_size=50, verbose=1) \n",
    "    results = cross_val_score(estimator=neural_network, X=train_data, y=train_targets, cv=6)\n",
    "\n",
    "    print(results)\n",
    "    print(results.mean())\n",
    "    print(results.std())'''\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def embeddingwords():\n",
    "    maxlen = 1000\n",
    "    training_samples = 200\n",
    "    validation_samples = 10000\n",
    "    max_words = 10000\n",
    "\n",
    "    train_data = pd.read_csv('Data/accident_data.csv', delimiter=',', engine='python')\n",
    "    train_data = train_data['Accident Description']\n",
    "\n",
    "    train_data = train_data.str.replace('([\\d]+)\\.','')\n",
    "    train_data = train_data.str.lstrip()\n",
    "    \n",
    "    print(train_data[0:5])\n",
    "    train_targets = pd.read_csv('train_targets3.csv', delimiter= ',', engine='python')\n",
    "    one_hot = pd.get_dummies(train_targets, prefix='Degree')\n",
    "    train_targets = pd.concat([train_targets, one_hot], axis=1)\n",
    "    train_targets = train_targets.drop(['Degree of the injury'], axis=1)\n",
    "\n",
    "    tokenizer = Tokenizer(num_words=max_words)\n",
    "    tokenizer.fit_on_texts(train_data)\n",
    "    sequences = tokenizer.texts_to_sequences(train_data)\n",
    "\n",
    "    word_index = tokenizer.word_index\n",
    "    print('Found %s unique tokens.' % len(word_index))\n",
    "    train_data = pad_sequences(sequences, maxlen=maxlen)\n",
    "    \n",
    "    print('Shape of data tensor:', train_data.shape)\n",
    "    #train_data = preprocessing.sequence.pad_sequences(train_data, maxlen=max_len, padding='post')\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(10000, 8, input_length = maxlen))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(36, activation='relu'))\n",
    "    model.add(layers.Dropout(0.6))\n",
    "    model.add(Dense(16, activation='relu'))\n",
    "    model.add(layers.Dropout(0.6))\n",
    "    model.add(layers.Dense(4,activation='softmax'))\n",
    "    model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    history = model.fit(train_data,train_targets, epochs=20, batch_size=60, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Run this to obtain model summarry and accuracy'''\n",
    "'''Two models can be used. I suggest kfoldvalidation(), accuracies is better '''\n",
    "kfoldvalidation()\n",
    "#embeddingwords()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
